#!/bin/bash
# -------------------------------
# ğŸ§  Script khá»Ÿi Ä‘á»™ng Airflow Webserver + Scheduler
# -------------------------------

AIRFLOW_HOME="$HOME/WorkSpace/Python/spark-airflow-demo"
PORT=8080

echo "ğŸš€ Starting Airflow environment at: $AIRFLOW_HOME"

# KÃ­ch hoáº¡t environment náº¿u cáº§n
source /opt/homebrew/anaconda3/bin/activate spark_env

# Kiá»ƒm tra vÃ  khá»Ÿi táº¡o DB náº¿u chÆ°a cÃ³
if [ ! -f "$AIRFLOW_HOME/airflow.db" ]; then
  echo "ğŸ—„ Initializing Airflow database..."
  airflow db migrate
fi

# Kiá»ƒm tra port 8080 cÃ³ bá»‹ chiáº¿m khÃ´ng
if lsof -Pi :$PORT -sTCP:LISTEN -t >/dev/null ; then
  echo "âš ï¸ Port $PORT is already in use. Kill old process first."
  exit 1
fi

# Cháº¡y webserver vÃ  scheduler trong background
echo "ğŸŒ Starting Airflow webserver on port $PORT..."
airflow webserver -p $PORT > "$AIRFLOW_HOME/log_webserver.txt" 2>&1 &

echo "â° Starting Airflow scheduler..."
airflow scheduler > "$AIRFLOW_HOME/log_scheduler.txt" 2>&1 &

echo "âœ… Airflow started successfully!"
echo "   ğŸŒ Web UI: http://localhost:$PORT"
echo "   ğŸ§¾ Logs: $AIRFLOW_HOME/log_webserver.txt , log_scheduler.txt"
