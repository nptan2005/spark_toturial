{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0bef4e4",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# spark_minio_demo.py\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import col\n",
    "\n",
    "def main():\n",
    "    spark = SparkSession.builder \\\n",
    "        .appName(\"Spark MinIO Demo\") \\\n",
    "        .master(\"spark://spark-master:7077\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "    # cấu hình MinIO (S3 API)\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.access.key\", \"admin\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.secret.key\", \"admin123\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.endpoint\", \"http://minio:9000\")\n",
    "    spark._jsc.hadoopConfiguration().set(\"fs.s3a.path.style.access\", \"true\")\n",
    "\n",
    "    input_path = \"s3a://demo-bucket/input/sample.csv\"\n",
    "    output_path = \"s3a://demo-bucket/output/result\"\n",
    "\n",
    "    df = spark.read.option(\"header\", \"true\").csv(input_path)\n",
    "    print(\"== Input Data ==\")\n",
    "    df.show()\n",
    "\n",
    "    # transform\n",
    "    df2 = df.select(\n",
    "        col(\"id\"),\n",
    "        col(\"value\").cast(\"double\").alias(\"value_num\"),\n",
    "        (col(\"value\").cast(\"double\") * 2).alias(\"value_double\")\n",
    "    )\n",
    "\n",
    "    print(\"== Transformed Data ==\")\n",
    "    df2.show()\n",
    "\n",
    "    # write back\n",
    "    df2.write.mode(\"overwrite\").option(\"header\", \"true\").csv(output_path)\n",
    "    print(f\"Output saved to {output_path}\")\n",
    "\n",
    "    spark.stop()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()\n"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
