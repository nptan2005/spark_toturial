# Spark Environment Docker Compose

File [docker-compose.yml](docker-compose.yml) trong sub-project spark-airflow-demo c·∫•u h√¨nh m·ªôt m√¥i tr∆∞·ªùng **Spark + Kafka + MinIO + Postgres + Airflow + Atlas + Ranger + JupyterLab** ƒë·∫ßy ƒë·ªß, **_cross-platform_** (Windows/Mac/Linux) v·ªõi kh·∫£ nƒÉng ch·∫°y tr√™n Mac ARM th√¥ng qua platform: linux/amd64.
**_Note_**: l√† b·∫£ng b·ªï sung th√†nh ph·∫ßn Governance so v·ªõi sub project spark_env

## Spark Environment Architecture:
```txt
                                   +-----------------------+
                                   |       Keycloak        |
                                   |   SSO / OAuth2 (8085) |
                                   +-----------+-----------+
                                               |
                                               | OIDC Auth
                                               v
+-----------------------+        +-----------------------+        +------------------------+
|    Spark UI Proxy     |<------>|     Spark Master      |<------>|     Spark Worker(s)    |
|     OAuth2 (8084)     |        |   8080 (UI) / 7077    |        |        (8081)          |
+-----------+-----------+        +-----------+-----------+        +-----------+------------+
            ^                                ^                                ^
            |                                |                                |
            |                                | Spark Tasks                    |
            | OAuth2 Redirect                |                                |
            |                                |                                |
+-----------+-----------+          +----------+------------+       +-----------+------------+
|        JupyterLab     |          |      Airflow Web      |       |       Airflow Scheduler |
|       Notebook (8888) |          |     UI (8082)         |       |     + DAG Processor     |
+-----------+-----------+          +----------+------------+       +-----------+------------+
            |                                |                                |
            +-----------+--------------------+--------------+------------------+
                        |                                   |
                        |  Submit jobs / Read-Write data    |
                        v                                   v
                 +-------------------+               +-------------------+
                 |      MinIO        |               |     Postgres      |
                 |   S3 Storage      |               |  Metadata DB (5432)|
                 +---------+---------+               +----------+----------+
                           ^                                     ^
                           |                                     |
                           | Batch/Stream Data                   | Metadata
                           |                                     |
+--------------------------+-------------------------------------+--------------------------+
|                                         Kafka                                                      |
|                       +----------------+       +-------------------+                             |
|                       |   Zookeeper    |<----->|   Kafka Broker    |                             |
|                       |     (2181)     |       |  (9092 / 29092)   |                             |
+--------------------------+-------------------------------------+----------------------------------+
                           |
                           v
          +----------------+-------------------+
          |               Governance           |
          |-----------------------------------|
          | Ranger (6080) ‚Äî Policy / ABAC     |
          | Atlas  (21000) ‚Äî Data Lineage     |
          | Token Service (5001) ‚Äî JWT        |
          +-----------------------------------+

==================================================================================================
                        üîç  Monitoring + Observability Stack
==================================================================================================

+-------------------+       +--------------------+       +---------------------+
|     Prometheus    |<----->|    cAdvisor        |       | Nginx Exporter      |
|     (9090)        |       | Docker Metrics     |       | Internal Metrics    |
+---------+---------+       +---------+----------+       +----------+----------+
          |                           |                             |
          v                           v                             v
+-----------------------------------------------------------------------------------------------+
|                                           Loki                                                 |
|                                      (Logs Backend, 3100)                                      |
+-------------------------------------------+---------------------------------------------------+
                                            |
                                            v
                                   +----------------+
                                   |    Grafana     |
                                   |  Dashboards    |
                                   |     (3000)     |
                                   +----------------+
```
## Ki·∫øn tr√∫c h·ªá th·ªëng

![CDP Architecture](docs/images/architecture-visual.svg)


## C√°c th√†nh ph·∫ßn ƒë∆∞·ª£c c·∫•u h√¨nh:
### 1. Spark
#### 1.1. spark-master

* **Image:** bde2020/spark-master:3.3.0-hadoop3.3
* **Container Name:** spark-master
* **Ports:**
>>* 8080: Web UI c·ªßa Spark Master
>>* 7077: Port giao ti·∫øp Spark Worker
* **M√¥i tr∆∞·ªùng:**
>>* SPARK_MODE=master ‚Üí Ch·ªâ ƒë·ªãnh container l√† Master
>>* SPARK_PUBLIC_DNS=spark-master ‚Üí DNS n·ªôi b·ªô
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** Spark Master qu·∫£n l√Ω cluster, nh·∫≠n job t·ª´ client, ph√¢n ph·ªëi t·ªõi c√°c Spark Worker.
#### **·ª®ng d·ª•ng:** D√πng cho ch·∫°y c√°c job Spark (batch/streaming) n·ªôi b·ªô cluster.

#### 1.2. spark-worker

* **Image:** bde2020/spark-worker:3.3.0-hadoop3.3
* **Container Name:** spark-worker
* **Ports:**
>>* 8081: Web UI c·ªßa Spark Worker
* **M√¥i tr∆∞·ªùng:**
>>* SPARK_MASTER=spark://spark-master:7077 ‚Üí K·∫øt n·ªëi t·ªõi Spark Master
>>* Dependencies: depends_on: spark-master
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** Th·ª±c thi job ƒë∆∞·ª£c ph√¢n ph·ªëi t·ª´ Spark Master.
#### **·ª®ng d·ª•ng:** Ch·∫°y c√°c task Spark, h·ªó tr·ª£ t√≠nh to√°n ph√¢n t√°n.

### Spark cluster:
#### **Master (8080/7077):** ƒêi·ªÅu ph·ªëi c√°c job t·ªõi Worker
#### **Worker(s) (8081):** Th·ª±c thi job
#### **Lu·ªìng d·ªØ li·ªáu:** Nh·∫≠n job t·ª´ JupyterLab ho·∫∑c Airflow, ƒë·ªçc/ghi d·ªØ li·ªáu t·ª´/ƒë·∫øn MinIO ho·∫∑c Kafka.


### 2. Kafka
#### 2.1. zookeeper

* **Image:** zookeeper:3.7.1
* **Container Name:** zookeeper
* **Ports:**
>>* 2181: Port client Zookeeper
* **M√¥i tr∆∞·ªùng:**
>>* ALLOW_ANONYMOUS_LOGIN=yes ‚Üí Cho ph√©p client k·∫øt n·ªëi kh√¥ng c·∫ßn user/password
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** Qu·∫£n l√Ω cluster Kafka, l∆∞u tr·ªØ metadata v·ªÅ topics, offsets.
#### **·ª®ng d·ª•ng:** C∆° s·ªü h·∫° t·∫ßng cho message broker c·ªßa Spark Streaming.

#### 2.2. kafka

* **Image:** wurstmeister/kafka:2.13-2.8.1
* **Container Name:** kafka
* **Ports:**
>>* 9092: Port client Kafka
* **M√¥i tr∆∞·ªùng:**
>>* KAFKA_ADVERTISED_LISTENERS=PLAINTEXT://localhost:9092 ‚Üí Kafka client k·∫øt n·ªëi qua localhost
>>* KAFKA_ZOOKEEPER_CONNECT=zookeeper:2181 ‚Üí K·∫øt n·ªëi Zookeeper
>>* KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR=1 ‚Üí Replication factor
* **Dependencies:** depends_on: zookeeper
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** Message broker, truy·ªÅn d·ªØ li·ªáu streaming t·ªõi Spark.
#### **·ª®ng d·ª•ng:** Th√≠ nghi·ªám real-time data pipeline v·ªõi Spark Streaming.

### 3. MinIO (Data Lake)

* **Image:** minio/minio
* **Container Name:** minio
* **Ports:**
>>* 9000: REST API
>>* 9001: Web Console
* **Volumes:** ./data/minio:/data
* **Command:** server /data --console-address ":9001"
* **M√¥i tr∆∞·ªùng:**
>>* MINIO_ROOT_USER=admin
>>* MINIO_ROOT_PASSWORD=admin123
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** 
>>* Object storage gi·ªëng S3 ƒë·ªÉ l∆∞u tr·ªØ d·ªØ li·ªáu th√≠ nghi·ªám.
>>* Data Lake l∆∞u tr·ªØ dataset, output Spark jobs.
#### **·ª®ng d·ª•ng:** L∆∞u tr·ªØ input/output Spark, dataset l·ªõn.
#### **Lu·ªìng d·ªØ li·ªáu:**
>>* Spark ƒë·ªçc/ghi d·ªØ li·ªáu batch/streaming
>>* JupyterLab ƒë·ªçc d·ªØ li·ªáu m·∫´u ƒë·ªÉ demo

### 4. Postgres (Airflow Metadata DB)

* **Image:** postgres:13
* **Container Name:** postgres
* **Ports:** 5432 ‚Üí Port DB
* **Volumes:** ./data/postgres:/var/lib/postgresql/data
* **M√¥i tr∆∞·ªùng:**
>>* POSTGRES_USER=airflow
>>* POSTGRES_PASSWORD=airflow
>>* POSTGRES_DB=airflow
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** 
>>* L∆∞u tr·ªØ metadata Airflow (DAGs, task status).
>>* Metadata DB cho Airflow, l∆∞u tr·∫°ng th√°i DAG v√† task logs.
#### **·ª®ng d·ª•ng:** Qu·∫£n l√Ω l·ªãch tr√¨nh workflow.

### 5. Airflow

* **Image:** apache/airflow:2.10.5-python3.12
* **Container Name:** airflow
* **Ports:** 8082:8080 ‚Üí Airflow web UI
* **Volumes:**
>>* ./dags:/opt/airflow/dags
>>* ./logs:/opt/airflow/logs
>>* ./plugins:/opt/airflow/plugins
* **M√¥i tr∆∞·ªùng:**
>>* AIRFLOW__CORE__EXECUTOR=LocalExecutor
>>* AIRFLOW__DATABASE__SQL_ALCHEMY_CONN=postgresql+psycopg2://airflow:airflow@postgres/airflow
>>* AIRFLOW__CORE__FERNET_KEY=...
>>* AIRFLOW__CORE__LOAD_EXAMPLES=False
>>* AIRFLOW__CORE__DAGS_ARE_PAUSED_AT_CREATION=True
* **Dependencies:** depends_on: postgres
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** 
>>* Orchestration workflow, ch·∫°y DAG, ƒëi·ªÅu ph·ªëi jobs.
>>* Orchestrator workflow, ch·∫°y DAGs, schedule jobs.
#### **·ª®ng d·ª•ng:** K·∫øt h·ª£p Spark + Kafka + MinIO pipeline.
#### **Lu·ªìng d·ªØ li·ªáu:** T∆∞∆°ng t√°c v·ªõi Spark cluster, l∆∞u metadata task status v√†o Postgres.

### 6. JupyterLab

* **Image:** jupyter/pyspark-notebook:latest
* **Container Name:** jupyterlab
* **Ports:** 8888:8888 ‚Üí Web Notebook
* **Volumes:** ./data:/home/jovyan/data
* **M√¥i tr∆∞·ªùng:**
>>* SPARK_MASTER=spark://spark-master:7077
>>* PYSPARK_PYTHON=python3
* **M·∫°ng:** spark-net
#### **Vai tr√≤:** 
>>* Notebook m√¥i tr∆∞·ªùng t∆∞∆°ng t√°c cho PySpark.
>>* Notebook t∆∞∆°ng t√°c cho PySpark, ch·∫°y th·ª≠ code batch/streaming.
#### **·ª®ng d·ª•ng:** Th·ª±c h√†nh, demo, vi·∫øt code Spark, Kafka streaming, MinIO.
#### **Lu·ªìng d·ªØ li·ªáu:** G·ª≠i Spark job t·ªõi cluster (spark://spark-master:7077) v√† ƒë·ªçc/ghi d·ªØ li·ªáu t·ªõi MinIO.

### 7. Network

* **Name:** spark-net
* **Driver:** bridge
#### **Vai tr√≤:** Cho ph√©p t·∫•t c·∫£ container giao ti·∫øp n·ªôi b·ªô, ƒë·∫£m b·∫£o Spark Master/Worker, Kafka, Airflow, JupyterLab k·∫øt n·ªëi li·ªÅn m·∫°ch.

### 8. Governance Layer

* **Atlas** (21000)
>* Metadata catalog, lineage tracking cho data pipeline.
>* T√≠ch h·ª£p v·ªõi Spark & Airflow.
* **Ranger** (6080)
>* Policy-based access control (ABAC)
>* Qu·∫£n l√Ω quy·ªÅn truy c·∫≠p data lake, Spark jobs.
* **Token Service** (5001)
>* JWT token provider cho Spark UI Proxy v√† c√°c service kh√°c.

### 9. Monitoring
#### 9.1. Prometheus
>* Image: prom/prometheus:latest
>* Container Name: prometheus
>* Ports: 9090:9090 ‚Üí Prometheus UI
>* Volumes: ./monitoring/prometheus.yml:/etc/prometheus/prometheus.yml
>* M·∫°ng: spark-net

**Vai tr√≤:**
* Thu th·∫≠p metrics t·ª´ Spark, Kafka, Nginx exporter, cAdvisor.
* L∆∞u time-series metrics cho Grafana.

**·ª®ng d·ª•ng:**
* Gi√°m s√°t CPU, RAM, network c·ªßa container.
* Tracking Spark executor usage, Kafka broker, Airflow scheduler metrics.

**Lu·ªìng d·ªØ li·ªáu:**
* Prometheus pull metrics t·ª´ exporters ‚Üí push sang Grafana dashboards.

‚∏ª

#### 9.2 Loki (Log Backend)
>* Image: grafana/loki:2.8.2
>* Container Name: loki
>* Ports: 3100:3100
>* Volumes: ./monitoring/loki-config.yml:/etc/loki/local-config.yml

**Vai tr√≤:**
* L∆∞u tr·ªØ to√†n b·ªô log ·ª©ng d·ª•ng: Spark, Kafka, Airflow, Nginx, Token Service, Docker logs.

**·ª®ng d·ª•ng:**
* Truy v·∫•n log b·∫±ng LogQL.
* L√† backend log cho Grafana Explore.

**Lu·ªìng d·ªØ li·ªáu:**
* Promtail ‚Üí g·ª≠i log ƒë·∫øn Loki ‚Üí Grafana ƒë·ªçc t·ª´ Loki.


#### 9.3 Promtail (Log Collector)
>* Image: grafana/promtail:2.8.2
>* Container Name: promtail
>* Volumes:
>>* ./monitoring/promtail-config.yml:/etc/promtail/config.yml
>>* ../logs:/logs (to√†n b·ªô log tr√™n host)

**Vai tr√≤:**
* Agent thu th·∫≠p log t·ª´ host v√† container.
* Parse log theo job (spark, kafka, nginx, airflow‚Ä¶).

**·ª®ng d·ª•ng:**
* Chuy·ªÉn qua Loki ƒë·ªÉ hi·ªÉn th·ªã trong Grafana.

**Lu·ªìng d·ªØ li·ªáu:**
* Log ‚Üí Promtail ‚Üí Loki ‚Üí Grafana.

#### 9.4  Grafana
>* Image: grafana/grafana:9.5.0
>* Container Name: grafana
>* Ports: 3000:3000
>* Volumes:
>>* grafana-storage:/var/lib/grafana
>>* ./monitoring/grafana/provisioning:/etc/grafana/provisioning
>>* ./monitoring/grafana/dashboards:/var/lib/grafana/dashboards

**Vai tr√≤:**
* Dashboard gi√°m s√°t to√†n h·ªá th·ªëng.
* Hi·ªÉn th·ªã metrics + log + health c·ªßa m·ªçi service.

**·ª®ng d·ª•ng:**
* Dashboard Spark, Kafka, Airflow, MinIO, Token Service.
* Live log stream t·ª´ Loki.

**Lu·ªìng d·ªØ li·ªáu:**
* Prometheus ‚Üí Metrics ‚Üí Grafana
* Loki ‚Üí Logs ‚Üí Grafana

#### 9.5  cAdvisor (Docker Metrics)
>* Image: gcr.io/google-containers/cadvisor:latest
>* Container Name: cadvisor
>* Expose: 8080
>* Volumes:
>>* /var/lib/docker (Docker engine)
>>* /sys, /var/run‚Ä¶

**Vai tr√≤:**
* Thu th·∫≠p metrics container-level:
* CPU
* RAM
* Disk I/O
* Network I/O

**·ª®ng d·ª•ng:**
* Xem real-time performance to√†n b·ªô stack Spark ‚Üí Airflow ‚Üí Kafka.

**Lu·ªìng d·ªØ li·ªáu:**
* cAdvisor ‚Üí Prometheus ‚Üí Grafana.

#### 9.6 Nginx Prometheus Exporter
>* Image: nginx/nginx-prometheus-exporter
>* Container Name: nginx-prometheus-exporter
>* Ports: 9113:9113
>* Scrape URI: http://access-host-proxy:8081/nginx_status

**Vai tr√≤:**
* Xu·∫•t metrics Nginx:
* request rate
* active connections
* dropped connections

**·ª®ng d·ª•ng:**
* Theo d√µi database proxy load, traffic ƒë·∫øn Airflow/Spark.

**Lu·ªìng d·ªØ li·ªáu:**
* Exporter ‚Üí Prometheus ‚Üí Grafana dashboard Nginx.

#### Monitoring Dashboard (JSON + Provisioning):
üîπ 1. Airflow Dashboard
	‚Ä¢	Scheduler delay
	‚Ä¢	DAG execution time
	‚Ä¢	Task duration
	‚Ä¢	Worker load

üîπ 2. Spark Dashboard
	‚Ä¢	Executors
	‚Ä¢	Jobs / Stages
	‚Ä¢	Task durations
	‚Ä¢	CPU/RAM usage

üîπ 3. Kafka Dashboard
	‚Ä¢	Broker health
	‚Ä¢	Consumer lag
	‚Ä¢	ISR / Under-replicated partitions

üîπ 4. Nginx Dashboard
	‚Ä¢	Requests per second
	‚Ä¢	Active connections
	‚Ä¢	Upstream latency

üîπ 5. Token Service Dashboard
	‚Ä¢	Response time
	‚Ä¢	Error rate

üîπ 6. Docker System Dashboard
	‚Ä¢	Per-container CPU, RAM
	‚Ä¢	Disk I/O
	‚Ä¢	Network usage

### 10. Lu·ªìng d·ªØ li·ªáu t·ªïng qu√°t
### 1. Batch/Interactive:
> JupyterLab ‚Üí Spark Master ‚Üí Spark Worker ‚Üí MinIO
### 2. Streaming:
> External Producer ‚Üí Kafka Broker ‚Üí Spark Streaming ‚Üí MinIO
### 3. Workflow scheduling:
> Airflow ‚Üí Spark jobs ‚Üí Worker ‚Üí MinIO/Postgres
### 4.Governance
> Atlas thu th·∫≠p lineage t·ª´ Spark & Airflow
> Ranger √°p d·ª•ng quy·ªÅn truy c·∫≠p
> Token Service c·∫•p JWT cho Spark UI Proxy v√† c√°c service kh√°c
### 5.SSO
> Keycloak qu·∫£n l√Ω ng∆∞·ªùi d√πng, OAuth2 cho Spark UI Proxy
### 6. Monitoring:
>* Spark Master UI (8080)
>* Spark Worker UI (8081)
>* Airflow Web UI (8082)
>* MinIO Console (9001)
>* Jupyter Notebook (8888)

### 11. L∆∞u √Ω v·∫≠n h√†nh

* **Cross-platform:** platform: linux/amd64 ƒë·∫£m b·∫£o ch·∫°y ƒë∆∞·ª£c tr√™n Mac ARM v√† Windows.
* **Volume mapping:** gi·ªØ d·ªØ li·ªáu persistent (Postgres, MinIO, Airflow logs, Jupyter data).
* **Start containers:**
  
#### C√°ch l·ªánh docker c∆° b·∫£n: 

```bash
docker-compose up -d
```
* **Stop containers:**
```bash
docker-compose down
```
* **Ki·ªÉm tra logs:**
```bash
docker logs -f <container_name>
```

#### Docker ki·ªÉm tra:

```bash
docker ps --format "table {{.Names}}\t{{.Status}}"
```

full

```bash
docker compose ps
```
### 12. Docker cleanup
#### üî• 1Ô∏è‚É£ Xo√° to√†n b·ªô log c·ªßa container (t·ª± ƒë·ªông gi·∫£m file JSON log)

Docker log n·∫±m ·ªü:
```
/var/lib/docker/containers/<container-id>/<container-id>-json.log
```
L·ªánh d·ªçn:
```bash
docker ps -aq | xargs -I {} sh -c 'truncate -s 0 /var/lib/docker/containers/{}/{}-json.log 2>/dev/null'
```
##### ‚ö†Ô∏è Note:
Tr√™n macOS, ƒë∆∞·ªùng d·∫´n th·ª±c t·∫ø n·∫±m trong VM, nh∆∞ng Docker Desktop h·ªó tr·ª£ truncate qua CLI.

* ‚úî Log s·∫Ω tr·ªü v·ªÅ 0 byte
* ‚úî Container kh√¥ng restart
* ‚úî Kh√¥ng m·∫•t d·ªØ li·ªáu volume

#### üî• 2Ô∏è‚É£ X√≥a container ƒë√£ d·ª´ng:

```bash
docker container prune -f
```

#### üî• 3Ô∏è‚É£ X√≥a image kh√¥ng d√πng (dangling + orphan)

```bash
docker image prune -a -f
```
N·∫øu mu·ªën xem tr∆∞·ªõc khi xo√°:
```bash
docker image prune -a
```
#### üî• 4Ô∏è‚É£ Xo√° network r√°c (docker-compose up/down nhi·ªÅu s·∫Ω sinh ra)
```bash
docker network prune -f
```
#### üî• 5Ô∏è‚É£ Xo√° volume r√°c (kh√¥ng c√≤n g·∫Øn v√†o container n√†o)

```bash
docker volume prune -f
```
>‚ö†Ô∏è L∆∞u √Ω: volume prune ch·ªâ xo√° volume kh√¥ng s·ª≠ d·ª•ng ‚Üí an to√†n.

#### üî• 6Ô∏è‚É£ Xo√° to√†n b·ªô build cache (r·∫•t n·∫∑ng, 2‚Äì20GB)
```bash
docker builder prune -a -f
```
#### üî• 7Ô∏è‚É£ X√≥a m·ªçi th·ª© kh√¥ng d√πng (CLEAN FULL)
```bash
docker system prune -a --volumes -f
```
>##### ‚ö†Ô∏è C·∫©n tr·ªçng:
>*	Xo√° t·∫•t c·∫£ container STOPPED
>*	Xo√° m·ªçi image kh√¥ng ƒë∆∞·ª£c container n√†o d√πng
>*	Xo√° network r√°c
>*	Xo√° build cache
>*	Xo√° volume kh√¥ng d√πng
>> Nh∆∞ng s·∫Ω kh√¥ng xo√° volume ƒëang mount cho project.

#### üî• 8Ô∏è‚É£ Ki·ªÉm tra dung l∆∞·ª£ng Docker sau khi d·ªçn
```bash
docker system df
```
ch·∫°y l·ªánh n√†y tr∆∞·ªõc ‚Üí ƒë·ªÉ xem c√°i g√¨ ƒëang chi·∫øm dung l∆∞·ª£ng:

output v√≠ d·ª•:
```
> docker system df
TYPE            TOTAL     ACTIVE    SIZE      RECLAIMABLE
Images          21        21        18.51GB   3.829GB (20%)
Containers      26        18        597.5MB   99.27MB (16%)
Local Volumes   50        7         390.2MB   321.5MB (82%)
Build Cache     55        0         2.936GB   2.936GB
```
#### üî• 9Ô∏è‚É£ Docker Desktop GUI c≈©ng c√≥ n√∫t d·ªçn cache
Settings ‚Üí Troubleshoot ‚Üí Clean/Purge Data
Nh∆∞ng CLI ch√≠nh x√°c h∆°n v√† tu·ª≥ ch·ªânh ƒë∆∞·ª£c.
#### ‚≠ê G·ª£i √Ω d·ªçn d·∫πp

V√¨ Project ƒëang build r·∫•t nhi·ªÅu docker image big-size (Spark, Airflow, Keycloak, Ranger, Atlas, Prometheus, Loki‚Ä¶), n√™n khuy√™n ch·∫°y:

G√≥i d·ªçn ti√™u chu·∫©n n√™n d√πng h·∫±ng ng√†y:
```bash
docker system prune -f
docker builder prune -f
docker volume prune -f
```
G√≥i d·ªçn to√†n b·ªô (1 tu·∫ßn/l·∫ßn)
```bash
docker system prune -a --volumes -f
```


## Truy c·∫≠p Web UI:

1. Spark Master: [http://localhost:8080](http://localhost:8080)
2. Spark Worker: [http://localhost:8081](http://localhost:8081)
3. Airflow: [http://localhost:8082](http://localhost:8082)
4. MinIO Console: [http://localhost:9001](http://localhost:9001)
5. JupyterLab: [http://localhost:8888](http://localhost:8888)

## T√†i li·ªáu c√†i ƒë·∫∑t v√† demo:

1. H∆∞·ªõng d·∫´n [c√†i ƒë·∫∑t v√† demo](Spark_governance.md)