# Spark Toturial:
```css
spark_workspace/
â”‚
â”œâ”€ environment.yml
â”œâ”€ start_spark_lab.bat      â† dÃ¹ng trÃªn Windows
â”œâ”€ start_spark_lab.sh       â† dÃ¹ng trÃªn macOS/Linux
â”‚
â”œâ”€ notebooks/               â† nÆ¡i chá»©a Jupyter notebooks
â”‚    â”œâ”€ spark_intro.ipynb
â”‚    â”œâ”€ streaming_kafka.ipynb
â”‚
â””â”€ data/                    â† data máº«u / input
        â”œâ”€ sample_data.csv
        â”œâ”€ kafka_messages.txt
```

# Táº¡o mÃ´i trÆ°á»ng tÃªn "spark_env" vá»›i Python 3.10
```bash
conda create -n spark_env python=3.10 -y
```

# KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
```bash
conda activate spark_env
```

# CÃ i Spark vÃ  cÃ¡c thÆ° viá»‡n cáº§n thiáº¿t
```bash
pip install pyspark findspark jupyterlab pandas numpy pyarrow
```

# delta tables hoáº·c streaming:
```bash
pip install delta-spark kafka-python
```

# Kiá»ƒm tra cÃ i Ä‘áº·t Spark

```bash
python -c "import pyspark; print(pyspark.__version__)"
```

# Test session
```python
from pyspark.sql import SparkSession

spark = SparkSession.builder \
    .appName("TestSpark") \
    .getOrCreate()

print("Spark version:", spark.version)
spark.stop()
```

# Thiáº¿t láº­p biáº¿n mÃ´i trÆ°á»ng

```bash
export PYSPARK_PYTHON=$(which python)
export PYSPARK_DRIVER_PYTHON=jupyter
export PYSPARK_DRIVER_PYTHON_OPTS="lab"
```


# Táº¡o biáº¿n mÃ´i trÆ°á»ng báº±ng file environment.yml:
```yaml
name: spark_env
channels:
  - conda-forge
  - defaults
dependencies:
  # --- Python core ---
  - python=3.10
  - pip
  - numpy
  - pandas
  - pyarrow
  - openjdk=11        # cáº§n cho Spark local mode (Java runtime)
  - jupyterlab
  - ipykernel
  - requests
  - tqdm
  - setuptools
  - wheel

  # --- PIP packages ---
  - pip:
      - pyspark==3.5.1
      - findspark
      - delta-spark
      - kafka-python
      - boto3
      - google-cloud-storage
      - azure-storage-blob
      - sqlalchemy
      - pyodbc
      - oracledb
      - pymysql
```

## ğŸ’¡ Ghi chÃº:

* openjdk=11: Spark 3.5 yÃªu cáº§u Java 11.
* delta-spark: náº¿u báº¡n cÃ³ dÃ¹ng Delta Lake (cho realtime/CDC).
* kafka-python: Ä‘á»ƒ káº¿t ná»‘i Apache Kafka topic.
* oracledb + pyodbc: Ä‘á»ƒ Ä‘á»c/ghi dá»¯ liá»‡u vá»›i Oracle, SQL Server.
* azure-storage-blob, google-cloud-storage, boto3: Ä‘á»ƒ Ä‘á»c ghi file trÃªn Cloud (Azure, GCP, AWS).

## CÃ¡ch sá»­ dá»¥ng file:
```makefile
D:\WorkSpace\Python\spark_toturial\environment.yml
```
## Táº¡o mÃ´i trÆ°á»ng Conda
```bash
conda env create -f environment.yml
```
## KÃ­ch hoáº¡t mÃ´i trÆ°á»ng
```bash
conda activate spark_env
```
## Kiá»ƒm tra
```bash
python -c "import pyspark; print(pyspark.__version__)"
```

# ğŸ§  3ï¸âƒ£ (Tuá»³ chá»n) Cháº¡y Spark vá»›i JupyterLab:

## Ä‘Äƒng kÃ½ kernel Ä‘á»ƒ dÃ¹ng trong Jupyter
```bash
python -m ipykernel install --user --name spark_env --display-name "Spark (PySpark 4.0.1)"
```
## khá»Ÿi Ä‘á»™ng JupyterLab
```bash
jupyter lab
```

# ğŸ”’ 4ï¸âƒ£ Báº£o máº­t & tÆ°Æ¡ng thÃ­ch (náº¿u báº¡n Ä‘ang trong mÃ´i trÆ°á»ng ngÃ¢n hÃ ng)

* Dá»¯ liá»‡u nháº¡y cáº£m â†’ nÃªn disable internet access cá»§a Conda environment (dÃ¹ng mirror ná»™i bá»™).

* Náº¿u cluster Spark dÃ¹ng Kerberos / LDAP â†’ cÃ i thÃªm:

```bash
pip install requests-kerberos pyspnego
```

* Náº¿u cáº§n giao tiáº¿p SFTP hoáº·c SSH:
```bash
pip install paramiko pysftp  
```

# Delta Lake hoáº·c Kafka Streaming
```bash
pip install "delta-spark>=3.2.0" "kafka-python>=2.0.2"
```

# Khi cháº¡y trÃªn Windows, Ä‘á»ƒ trÃ¡nh lá»—i â€œWinUtils not foundâ€, cÃ³ thá»ƒ cÃ i thÃªm gÃ³i giáº£ láº­p:
```bash
pip install winutils
```

## Window - Java báº±ng pip (cÃ¡ch dá»± phÃ²ng):

```bash
pip install jdk4spark
```
â†’ ThÆ° viá»‡n nÃ y chá»©a JRE 11 tá»‘i giáº£n, tá»± Ä‘á»™ng giáº£i nÃ©n vÃ o .local/jdk trong user folder.

Sau Ä‘Ã³ thÃªm biáº¿n:

```bat
SET JAVA_HOME=%USERPROFILE%\.local\jdk
SET PATH=%JAVA_HOME%\bin;%PATH%
```

## Git merge:
### ğŸš€ local lÃªn GitHub:
```bash
git push origin main
```
### ğŸ’¡ Kiá»ƒm tra nhanh branch tracking:
```bash
git branch -vv
```
### âš™ï¸ 1ï¸âƒ£ Thiáº¿t láº­p branch main tracking Ä‘Ãºng origin/main
```bash
git branch --set-upstream-to=origin/main main
```
### âš™ï¸ 2ï¸âƒ£ Thiáº¿t láº­p hÃ nh vi pull chuáº©n
1. Äá»ƒ git pull luÃ´n tá»± Ä‘á»™ng rebase thay vÃ¬ merge (giá»¯ lá»‹ch sá»­ gá»n gÃ ng), báº¡n nÃªn báº­t:
Thay vÃ¬ merge, Git Ä‘Æ°a cÃ¡c commit local lÃªn Ä‘áº§u cá»§a nhÃ¡nh remote má»›i nháº¥t:
```css
A---B---C (local)
     \
      D---E (remote)
```
Sau git pull --rebase, Git â€œchuyá»ƒnâ€ commit local lÃªn sau E:
```css
A---B---D---E---C'
```
#### ğŸŸ¢ Æ¯u Ä‘iá»ƒm:
	*	Lá»‹ch sá»­ tháº³ng hÃ ng, sáº¡ch Ä‘áº¹p (linear history).
	*	Dá»… Ä‘á»c, dá»… tÃ¬m lá»—i khi review hoáº·c bisect.

#### ğŸ”´ NhÆ°á»£c Ä‘iá»ƒm:
	*	KhÃ´ng nÃªn rebase commit Ä‘Ã£ â€œpushâ€ cÃ´ng khai (vÃ¬ sáº½ thay Ä‘á»•i hash commit).
```bash
git config --global pull.rebase true
```
1. Náº¿u báº¡n thÃ­ch kiá»ƒu merge  (Ã­t thay Ä‘á»•i hÆ¡n), thÃ¬ dÃ¹ng:

```css
A---B---C (local)
     \
      D---E (remote)
```

sau git pull (merge) sáº½ thÃ nh:

```css
A---B---C--------M
     \          /
      D---E----/
```
#### ğŸŸ¢ Æ¯u Ä‘iá»ƒm:
	* Giá»¯ nguyÃªn lá»‹ch sá»­ thá»±c táº¿ (bao gá»“m cáº£ nhÃ¡nh merge).
	* Dá»… xem ai merge, khi nÃ o merge.
#### ğŸ”´ NhÆ°á»£c Ä‘iá»ƒm:
	*	Lá»‹ch sá»­ lá»™n xá»™n, khÃ³ Ä‘á»c vá»›i nhiá»u â€œmerge commitâ€ dÆ° thá»«a.
	*	Khi lÃ m teamwork, log nhÃ¬n sáº½ â€œrá»‘iâ€ (nhiá»u nhÃ¡nh giao nhau).


```bash
git config --global pull.rebase false
```
1. âš™ï¸ 3ï¸âƒ£ Thiáº¿t láº­p â€œpush defaultâ€ Ä‘á»ƒ Git tá»± Ä‘á»™ng Ä‘áº©y Ä‘Ãºng nhÃ¡nh
```bash
git config --global push.default current
```
>NghÄ©a lÃ : náº¿u báº¡n Ä‘ang á»Ÿ main â†’ git push sáº½ tá»± push lÃªn origin/main.

### âœ… Kiá»ƒm tra láº¡i cáº¥u hÃ¬nh
Báº¡n cÃ³ thá»ƒ xem toÃ n bá»™ config:
```bash
git config --list --show-origin
```
Hoáº·c chá»‰ xem cÃ¡c dÃ²ng liÃªn quan:
```bash
git config --global --get pull.rebase
git config --global --get push.default
```
### âš™ï¸ Sá»­ dá»¥ng:
#### Náº¿u lÃ m má»™t mÃ¬nh hoáº·c code cÃ¡ nhÃ¢n â†’ nÃªn dÃ¹ng:
```bash
git config --global pull.rebase true
```
>(giÃºp lá»‹ch sá»­ gá»n, dá»… hiá»ƒu)

#### Náº¿u lÃ m team cÃ³ merge request / pull request rÃµ rÃ ng â†’ nÃªn dÃ¹ng:
```bash
git config --global pull.rebase false
```
>(giá»¯ nguyÃªn merge commit Ä‘á»ƒ trace dá»… dÃ ng)


# Airflow:

## Start:

```bash
airflow webserver -p 8080
```

```bash
airflow scheduler
```

cháº¡y ná»n

```bash
airflow standalone
```

## ğŸ›‘ Dá»«ng táº¥t cáº£ tiáº¿n trÃ¬nh Airflow:

```bash
pkill -f "airflow webserver"
pkill -f "airflow scheduler"
```
Hoáº·c náº¿u báº¡n muá»‘n dá»«ng toÃ n bá»™:

```bash
pkill -f airflow
```
âœ… Sau Ä‘Ã³, kiá»ƒm tra láº¡i:

```bash
ps aux | grep airflow
```

## ğŸ§¼ (Tuá»³ chá»n) Dá»n log & DB náº¿u muá»‘n reset sáº¡ch

```bash
rm -rf /Users/nptan2005/airflow/airflow.db
rm -rf /Users/nptan2005/airflow/logs/*
```

## Táº¡o connection Spark trong Airflow
```bash
airflow connections add 'spark_default' \
    --conn-type 'spark' \
    --conn-host 'local[*]' \
    --conn-extra '{"queue":"default"}'
```